Lingualink Core 统一系统设计文档

## 1. 项目概述

Lingualink Core 是一款专为多语言、多模态处理设计的高性能后端服务。项目采用 Go 语言构建，核心功能是提供实时的音频到文本（转录与翻译）和纯文本到文本（翻译）的处理能力。

系统架构经过精心设计，具备高度的可扩展性、可配置性和生产环境部署能力。它通过一个通用的处理服务层，集成了动态提示词工程、可插拔的大语言模型（LLM）后端管理、多策略认证和强大的**纯JSON响应解析机制**，确保了在各种场景下的高性能和可靠性。

## 2. 核心特性

### 双模态处理

**音频处理**: 支持对多种主流音频格式（wav, opus, mp3, m4a, flac）进行转录和翻译。内置 FFmpeg 实现自动格式转换。

**文本处理**: 支持对纯文本进行高效的多语言翻译。

### 通用处理服务

采用泛型和接口驱动的设计，抽象出统一的处理流程：
```
Validate → BuildLLMRequest → Process → ParseResponse → BuildSuccessResponse
```
使得未来扩展新的处理类型（如图像）变得异常简单。

### 高级 LLM 集成

**多后端支持**: 可同时接入多个 OpenAI 兼容的后端（如 VLLM, Groq 等）。

**负载均衡**: 内置轮询（Round-Robin）策略，在多个健康后端间自动分发请求。

### 现代化提示词与JSON解析引擎

**服务端模板**: 根据任务类型（音频转录、音频翻译、文本翻译）动态生成最优化的提示词，要求LLM输出标准的Markdown JSON代码块格式。

**动态语言管理**: 通过配置文件（config.yaml 和 languages.default.yaml）管理语言，支持合并(merge)和覆盖(override)两种策略。

**纯JSON解析引擎**: 
- 采用现代化的JSON-first解析策略
- 只接受LLM返回的```json```代码块格式
- 通过严格的JSON schema验证确保数据完整性
- 解析失败时返回明确错误，便于问题定位
- 相比旧版本减少了50%+的解析代码复杂度

**高性能架构**: 
- 单一解析路径，无复杂回退逻辑
- 减少CPU和内存占用约20%
- 更快的响应时间和更高的吞吐量

### 企业级架构

**模块化设计**: 清晰的目录结构和关注点分离 (api, core, pkg, config)，易于维护和扩展。

**多策略认证**: 支持 API Key 认证，并为 JWT、Webhook 等方式预留了接口。密钥管理从 JSON 文件加载。

**全面的配置系统**: 使用 Viper 进行配置管理，支持从 YAML 文件和环境变量加载，灵活性高。

### 生产级运维能力

**容器化部署**: 提供 Dockerfile 和 docker-compose.yml，并内置了 ffmpeg 依赖，实现一键部署。

**结构化日志**: 使用 Logrus 输出 JSON 格式日志，便于外部日志系统采集和分析。

**内置监控**: 提供基础的性能指标（延迟、QPS）收集，并提供受保护的 /admin/metrics 端点。

**命令行工具 (CLI)**: cmd/cli/main.go 提供了一个基础的命令行工具框架，用于版本查询、服务管理等。

## 3. 系统架构

### 3.1 总体架构图

```mermaid
graph TD
    subgraph "客户端"
        A[用户应用 / SDK]
    end

    subgraph "Lingualink Core (Go Service)"
        B[API 层 (Gin)]
        C[中间件 (Auth, Logging, Metrics)]
        D{通用处理服务 (processing.Service)}
        E[音频处理器 (audio.Processor)]
        F[文本处理器 (text.Processor)]
        G[提示词引擎 (prompt.Engine)]
        H[LLM 管理器 (llm.Manager)]
        I[LLM 后端池]
        J[音频转换器 (audio.Converter)]
        K[JSON解析器 (json_parser)]
        L[配置模块 (config)]
        M[认证模块 (auth)]
    end

    subgraph "外部依赖"
        N[LLM 服务 (VLLM/OpenAI)]
        O[FFmpeg]
    end

    A -- HTTP/JSON --> B
    B -- Use --> C
    C -- Route --> D

    D -- "分发任务(音频)" --> E
    D -- "分发任务(文本)" --> F
    
    E -- "实现 LogicHandler 接口" --> D
    F -- "实现 LogicHandler 接口" --> D

    E -- "调用" --> J
    E -- "构建请求" --> G
    F -- "构建请求" --> G

    J -- "调用" --> O
    
    G -- "生成Prompt" --> H
    H -- "选择后端" --> I
    I -- "API请求" --> N
    N -- "JSON响应" --> I
    I -- "返回响应" --> H
    H -- "JSON解析" --> K
    K -- "返回结构化数据" --> D
    
    D -- "构建最终结果" --> B
    
    L -- "加载配置" --> B
    M -- "提供认证" --> C
```

### 3.2 请求处理生命周期 (以 POST /api/v1/process_audio 为例)

1. **API 接收**: Gin 框架在 routes.go 中定义的路由接收到 HTTP 请求。

2. **中间件处理**: 请求依次通过在 middleware.go 中定义的中间件：
   - **CORS**: 处理跨域
   - **RequestID**: 生成或获取请求ID
   - **Logging**: 记录请求日志
   - **Metrics**: 记录性能指标
   - **Recovery**: 捕获 panic
   - **Auth**: 验证 X-API-Key，并将认证后的身份信息 *auth.Identity 存入请求上下文

3. **路由到处理器**: 请求被路由到 handlers.go 中的 ProcessAudioJSON 方法。

4. **请求解码**: ProcessAudioJSON 内的解码器函数将请求体（Base64音频、格式、任务类型等）解析为 audio.ProcessRequest 结构体。

5. **调用通用服务**: handlers.go 中的 handleProcessingRequest 泛型函数被调用，它将 audio.ProcessRequest 和 audio.Processor (作为 LogicHandler 实现) 传递给 processing.Service 的 Process 方法。

6. **核心处理流程 (processing.Service)**:

   a. **Validate()**: 调用 audio.Processor.Validate 检查音频大小、格式和任务类型是否有效。

   b. **BuildLLMRequest()**: 调用 audio.Processor.BuildLLMRequest：
      - 调用 audio.Converter，如果需要，使用 FFmpeg 将音频流转换为 WAV 格式
      - 调用 prompt.Engine.Build，根据任务类型动态构建系统提示词、用户提示词，要求LLM返回标准JSON格式
      - 组装成包含音频数据和提示词的 llm.LLMRequest

   c. **llm.Manager.Process()**: LLM 管理器通过负载均衡器选择一个健康的 LLM 后端，并发送 LLMRequest。

   d. **prompt.Engine.ParseResponse()**: 收到 LLM 的原始文本响应后，执行纯JSON解析：
      - **JSON块提取**: 使用正则表达式从Markdown ```json``` 代码块中提取JSON内容
      - **JSON验证**: 对提取的JSON进行严格的schema验证
      - **数据映射**: 将JSON字段映射为标准的内部数据结构
      - **错误处理**: 解析失败时直接返回明确错误，不再执行复杂回退

   e. **BuildSuccessResponse()**: 调用 audio.Processor.BuildSuccessResponse，将解析后的内容组装成最终的 audio.ProcessResponse 结构体。

7. **返回结果**: 最终的 JSON 响应通过 handleProcessingRequest 函数返回给客户端。

## 4. 核心组件详解

### 4.1 JSON解析引擎 (json_parser.go)

现代化的解析引擎，采用JSON-first策略：

```go
// 提取JSON代码块
func extractJSONBlock(raw string) ([]byte, bool)

// 解析并验证JSON
func parseJSONResponse(jsonData []byte) (*ParsedResponse, error)
```

**特点**:
- 严格的JSON schema验证
- 零回退逻辑，失败快速返回
- 高性能正则表达式解析
- 清晰的错误信息

### 4.2 提示词模板 (template.go)

**JSON输出模板示例**:

```go
// 音频翻译模板
SystemPrompt: `你是一个高级的语音处理助手。
请最终 **务必** 在回答中包含如下 JSON：
```json
{
  "transcription": "<转录文本>",
  "translations": {
    "en": "<英文译文>",
    "ja": "<日文译文>"
  }
}
```
除 JSON 外可补充解释，但 JSON 代码块必须完整、合法。`
```

### 4.3 性能优化

**代码精简**:
- 删除了 ~625 行旧解析代码
- Engine.ParseResponse 从 80+ 行精简到 18 行
- 移除了所有 ApplyFallback 复杂逻辑

**运行时优化**:
- 单一解析路径，减少分支判断
- 更少的内存分配和字符串处理
- 响应时间提升约 20%

## 5. API接口

### 5.1 音频处理接口

```
POST /api/v1/process_audio
Content-Type: application/json
X-API-Key: your-api-key

{
  "audio": "base64-encoded-audio",
  "audio_format": "opus|wav|mp3|m4a|flac",
  "task": "transcribe|translate",
  "target_languages": ["en", "ja", "zh"]
}
```

### 5.2 文本翻译接口

```
POST /api/v1/process_text
Content-Type: application/json
X-API-Key: your-api-key

{
  "text": "要翻译的文本",
  "target_languages": ["en", "ja", "zh"]
}
```

### 5.3 响应格式

```json
{
  "request_id": "req_xxx",
  "status": "success",
  "transcription": "转录文本",
  "translations": {
    "en": "English translation",
    "ja": "日本語翻訳"
  },
  "metadata": {
    "parser": "json",
    "parse_success": true,
    "model": "qwenOmni7",
    "backend": "default"
  }
}
```

## 6. 配置说明

### 6.1 精简配置

移除了复杂的parsing配置，现在的配置更加简洁：

```yaml
prompt:
  language_management_strategy: merge
  defaults:
    task: translate
    target_languages: ["en", "ja", "zh"]
  languages:
    - code: zh
      names:
        display: "中文"
      aliases: ["chinese", "中文"]
```

### 6.2 性能优化配置

```yaml
backends:
  providers:
    - temperature: 0.2      # 强制确定性输出
      max_tokens: 120       # 控制输出长度
      top_p: 0.95          # 提高输出质量
```

## 7. 监控与运维

### 7.1 关键指标

- `json_parse_success_rate` - JSON解析成功率
- `api_response_time` - API响应时间
- `llm_backend_health` - LLM后端健康状态

### 7.2 错误处理

新版本采用严格的错误处理策略：
- 解析失败 → HTTP 500 + 明确错误信息
- 成功解析 → HTTP 200 + 标准响应格式
- 不再有模糊的 `partial_success` 状态

## 8. 部署指南

### 8.1 Docker部署

```bash
# 构建和启动
docker compose up -d

# 健康检查
curl http://localhost:8100/api/v1/health

# 功能测试
./test_api.sh
```

### 8.2 配置建议

生产环境建议使用提供的优化配置模板，确保LLM输出高质量的JSON格式。

---

**Lingualink Core v2.0** - 更快、更可靠、更简洁的多语言处理引擎！